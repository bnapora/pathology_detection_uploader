{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Register model and deploy locally with advanced usages\n",
        "\n",
        "This example shows how to deploy a web service in step-by-step fashion:\n",
        "\n",
        " 1. Register model\n",
        " 2. Deploy the image as a web service in a local Docker container.\n",
        " 3. Quickly test changes to your entry script by reloading the local service.\n",
        " 4. Optionally, you can also make changes to model, conda or extra_docker_file_steps and update local service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the [configuration](../../../configuration.ipynb) Notebook first if you haven't."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "subscription_id = os.getenv(\"40bffbcc-578f-4e44-bd6d-972552eb6513\", default=\"40bffbcc-578f-4e44-bd6d-972552eb6513\")\n",
        "resource_group = os.getenv(\"gestaltml\", default=\"gestaltml\")\n",
        "workspace_name = os.getenv(\"fastai2\", default=\"fastai2\")\n",
        "workspace_region = os.getenv(\"eastus\", default=\"eastus\")\n",
        "\n",
        "score_script = 'score_local.py'\n",
        "model_name = 'breastcancerfastai_local03'\n",
        "service_name = 'breastcancerlocal03'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.13.0\n"
        }
      ],
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Workspace\n",
        "\n",
        "Initialize a workspace object from persisted configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "fastai2\ngestaltml\neastus\n40bffbcc-578f-4e44-bd6d-972552eb6513\n"
        }
      ],
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.get(name=workspace_name, subscription_id=subscription_id, resource_group=resource_group)\n",
        "\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create trained model\n",
        "\n",
        "For this example, we will train a small model on scikit-learn's [diabetes dataset](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import joblib\n",
        "\n",
        "# from sklearn.datasets import load_diabetes\n",
        "# from sklearn.linear_model import Ridge\n",
        "\n",
        "# dataset_x, dataset_y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# sk_model = Ridge().fit(dataset_x, dataset_y)\n",
        "\n",
        "# joblib.dump(sk_model, \"sklearn_regression_local.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can add tags and descriptions to your models. we are using `sklearn_regression_model.pkl` file in the current directory as a model with the name `sklearn_regression_model` in the workspace.\n",
        "\n",
        "Using tags, you can track useful information such as the name and version of the machine learning library used to train the model, framework, category, target customer etc. Note that tags must be alphanumeric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Registering model breastcancerfastai_local03\n"
        }
      ],
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "model = Model.register(model_path=\"export.pkl\",\n",
        "                       model_name=model_name,\n",
        "                       tags={'area': \"breast\", 'type': \"transfer-learning\", 'classes':'Positive,Negative'},\n",
        "                       description=\"Breast Cancer Diag-embeded X,Y functions:092220\",\n",
        "                       workspace=ws)"
      ]
    },
    {
      "source": [
        "## Open Existing Model<br>\n",
        "Use if model already installed in Azure ML Workspace"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# from azureml.core import Model\n",
        "# from azureml.core.resource_configuration import ResourceConfiguration\n",
        "\n",
        "# model = Model(ws, model_name)\n",
        "\n",
        "# print('Name:', model.name)\n",
        "# print('Version:', model.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Manage your dependencies in a folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "source_directory = \"source_directory\"\n",
        "\n",
        "os.makedirs(source_directory, exist_ok=True)\n",
        "os.makedirs(os.path.join(source_directory, \"x/y\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(source_directory, \"env\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(source_directory, \"dockerstep\"), exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display scoring file (var score_script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "import os, base64\nimport torch\nimport json\nfrom azureml.core.model import Model\nfrom azureml.core import Workspace\nimport fastai \n# from fastai.basics import *\nfrom fastai.vision.all import *\nfrom fastai.callback.all import *\n# from fastai.metrics import accuracy \n# from fastai.metrics import error_rate\nimport urllib.request\n\n    # global model\n\n    # # The AZUREML_MODEL_DIR environment variable indicates\n    # # a directory containing the model file you registered.\n    # model_filename = 'sklearn_regression_model.pkl'\n    # model_path = os.path.join(os.environ['AZUREML_MODEL_DIR'], model_filename)\n\n    # model = joblib.load(model_path)\n\ndef init():\n    global learner\n    # The AZUREML_MODEL_DIR environment variable indicates a directory containing the model file you registered.  \n    #this init works \n    pathsrc=Path()\n\n    model_path=os.getenv('AZUREML_MODEL_DIR')  \n    \n    filename=\"export.pkl\"\n    classes = ['Positive','Negative']\n    model_path_file = os.path.join(os.environ['AZUREML_MODEL_DIR'], filename)\n    model_path_hc = 'azureml-models/breastcancerfastai/1'\n    model_path_file_hc = './source_directory/azureml-models/breastcancerfastai/1/export.pkl'\n    print('AZUREML_MODEL_DIR-Model_Path: ' + model_path)\n    print('Model_Path_File: ' + model_path_file)\n    print('Model_Path_File_HC: ' + model_path_file_hc)\n    print('FastAI Version: ' + fastai.__version__)\n\n    print ('Path(): ' + str(pathsrc))\n\n    for filename in os.listdir(pathsrc):\n        print(filename)\n\n    for dirname, dirnames, filenames in os.walk(pathsrc):\n        # print path to all subdirectories first.\n        for subdirname in dirnames:\n            print(os.path.join(dirname, subdirname))\n\n        # print path to all filenames.\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\n    learner = load_learner(model_path_file_hc)\n    # classes = learner.data.classes\n    # print('Learner: ' + classes)\n\n\ndef run(raw_data):\n    # base64_string = json.loads(raw_data)['data']\n    # base64_bytes = base64.b64decode(base64_string)\n    # with open(os.path.join(os.getcwd(),\"score.jpg\"), 'wb') as f:\n    #     f.write(base64_bytes)\n    \n    # make prediction\n    #img = open_image(os.path.join(os.getcwd(),\"score.jpg\"))\n    #result = learn.predict(img)\n    result = 'Test,Positive'\n    # return json.dumps({'class':str(result[0]), 'probs':result[2].data[1].item()})\n    return result\n"
        }
      ],
      "source": [
        "with open(score_script) as f:\n",
        "    print(f.read())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# %%writefile source_directory/extradata.json\n",
        "# {\n",
        "#     \"people\": [\n",
        "#         {\n",
        "#             \"website\": \"microsoft.com\", \n",
        "#             \"from\": \"Seattle\", \n",
        "#             \"name\": \"Mrudula\"\n",
        "#         }\n",
        "#     ]\n",
        "# }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Inference Configuration\n",
        "\n",
        " - file_path: input parameter to Environment constructor. Manages conda and python package dependencies.\n",
        " - env.docker.base_dockerfile: any extra steps you want to inject into docker file\n",
        " - source_directory: holds source path as string, this entire folder gets added in image so its really easy to access any files within this folder or subfolder\n",
        " - entry_script: contains logic specific to initializing your model and running predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create environment\n",
        "\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "entryscript_fullpath = \"x/y/\" + str(score_script)\n",
        "\n",
        "myenv = Environment(model_name)\n",
        "myenv.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
        "    'azureml-defaults~=1.13.0', 'fastcore==1.0.0', 'fastprogress==1.0.0', 'fastscript==1.0.0', 'Pillow==5.4.1', 'requests', 'torch==1.6.0', 'torchvision>=0.5.0', 'fastai==2.0.6', 'ipython'\n",
        "])\n",
        "# explicitly set base_image to None when setting base_dockerfile\n",
        "myenv.docker.base_image = None\n",
        "myenv.docker.base_dockerfile = \"FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\\nRUN echo \\\"this is test\\\"\"\n",
        "myenv.inferencing_stack_version = \"latest\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Create inference config\n",
        "inference_config = InferenceConfig(source_directory=source_directory,                                 entry_script=entryscript_fullpath,\n",
        "    environment=myenv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy Model as a Local Docker Web Service\n",
        "\n",
        "*Make sure you have Docker installed and running.*\n",
        "\n",
        "Note that the service creation can take few minutes.\n",
        "\n",
        "NOTE:\n",
        "\n",
        "The Docker image runs as a Linux container. If you are running Docker for Windows, you need to ensure the Linux Engine is running:\n",
        "\n",
        "    # PowerShell command to switch to Linux engine\n",
        "    & 'C:\\Program Files\\Docker\\Docker\\DockerCli.exe' -SwitchLinuxEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading model breastcancerfastai_local03:1 to C:\\Users\\BRIANN~1\\AppData\\Local\\Temp\\azureml_cnyd49vv\\breastcancerfastai_local03\\1\nGenerating Docker build context.\nPackage creation Succeeded\nLogging into Docker registry 84659b36a99e4a16a8757ae52b4288dc.azurecr.io\nLogging into Docker registry 84659b36a99e4a16a8757ae52b4288dc.azurecr.io\nBuilding Docker image from Dockerfile...\nStep 1/5 : FROM 84659b36a99e4a16a8757ae52b4288dc.azurecr.io/azureml/azureml_e5a6bc09d9ffd8bce12ea2b9ad46d390\n ---> 7a313ce8cfc0\nStep 2/5 : COPY azureml-app /var/azureml-app\n ---> 7800a2bb5239\nStep 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjQwYmZmYmNjLTU3OGYtNGU0NC1iZDZkLTk3MjU1MmViNjUxMyIsInJlc291cmNlR3JvdXBOYW1lIjoiZ2VzdGFsdG1sIiwiYWNjb3VudE5hbWUiOiJmYXN0YWkyIiwid29ya3NwYWNlSWQiOiI4NDY1OWIzNi1hOTllLTRhMTYtYTg3NS03YWU1MmI0Mjg4ZGMifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n ---> Running in c89ebeb1bfb7\n ---> 69934aebaa9d\nStep 4/5 : RUN mv '/var/azureml-app/tmpv1cr_rmp.py' /var/azureml-app/main.py\n ---> Running in 4ba791ea1c0e\n ---> 43e7588a84ff\nStep 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n ---> Running in 464110845b5b\n ---> cab3e1028b98\nSuccessfully built cab3e1028b98\nSuccessfully tagged breastcancerlocal03:latest\nStarting Docker container...\nDocker container running.\nChecking container health...\nERROR - Error: Container has crashed. Did your init method fail?\n\n\nContainer Logs:\n2020-09-22T18:49:05,620850800+00:00 - rsyslog/run \n2020-09-22T18:49:05,621196600+00:00 - gunicorn/run \n2020-09-22T18:49:05,621614400+00:00 - iot-server/run \n2020-09-22T18:49:05,626889400+00:00 - nginx/run \n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2020-09-22T18:49:05,697065300+00:00 - iot-server/finish 1 0\n2020-09-22T18:49:05,698390100+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 19.9.0\nListening at: http://127.0.0.1:31311 (11)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 45\nSPARK_HOME not set. Skipping PySpark Initialization.\nGenerating new fontManager, this may take some time...\nInitializing logger\n2020-09-22 18:49:08,910 | root | INFO | Starting up app insights client\nStarting up app insights client\n2020-09-22 18:49:08,911 | root | INFO | Starting up request id generator\nStarting up request id generator\n2020-09-22 18:49:08,911 | root | INFO | Starting up app insight hooks\nStarting up app insight hooks\n2020-09-22 18:49:08,911 | root | INFO | Invoking user's init function\nInvoking user's init function\nAZUREML_MODEL_DIR-Model_Path: azureml-models/breastcancerfastai_local03/1\nModel_Path_File: azureml-models/breastcancerfastai_local03/1/export.pkl\nModel_Path_File_HC: ./source_directory/azureml-models/breastcancerfastai/1/export.pkl\nFastAI Version: 2.0.6\nPath(): .\nazureml-models\nsource_directory\n__pycache__\nmain.py\nmodel_config_map.json\n./azureml-models\n./source_directory\n./__pycache__\n./main.py\n./model_config_map.json\n./azureml-models/breastcancerfastai_local03\n./azureml-models/breastcancerfastai_local03/1\n./azureml-models/breastcancerfastai_local03/1/export.pkl\n./source_directory/azureml-models\n./source_directory/dockerstep\n./source_directory/env\n./source_directory/x\n./source_directory/azureml-models/breastcancerfastai\n./source_directory/azureml-models/breastcancerfastai/1\n./source_directory/azureml-models/breastcancerfastai/1/export_breast_092220.pkl\n./source_directory/x/y\n./source_directory/x/y/__pycache__\n./source_directory/x/y/score_local.py\n./source_directory/x/y/__pycache__/score_local.cpython-36.pyc\n./__pycache__/main.cpython-36.pyc\n2020-09-22 18:49:08,913 | root | ERROR | User's init function failed\nUser's init function failed\n2020-09-22 18:49:08,914 | root | ERROR | Encountered Exception Traceback (most recent call last):\n  File \"/var/azureml-server/aml_blueprint.py\", line 163, in register\n    main.init()\n  File \"/var/azureml-app/main.py\", line 35, in init\n    driver_module.init()\n  File \"/var/azureml-app/source_directory/x/y/score_local.py\", line 55, in init\n    learner = load_learner(model_path_file_hc)\n  File \"/azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/python3.6/site-packages/fastai/learner.py\", line 539, in load_learner\n    res = torch.load(fname, map_location='cpu' if cpu else None)\n  File \"/azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/python3.6/site-packages/torch/serialization.py\", line 571, in load\n    with _open_file_like(f, 'rb') as opened_file:\n  File \"/azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/python3.6/site-packages/torch/serialization.py\", line 229, in _open_file_like\n    return _open_file(name_or_buffer, mode)\n  File \"/azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/python3.6/site-packages/torch/serialization.py\", line 210, in __init__\n    super(_open_file, self).__init__(open(name, mode))\nFileNotFoundError: [Errno 2] No such file or directory: './source_directory/azureml-models/breastcancerfastai/1/export.pkl'\n\nEncountered Exception Traceback (most recent call last):\n  File \"/var/azureml-server/aml_blueprint.py\", line 163, in register\n    main.init()\n  File \"/var/azureml-app/main.py\", line 35, in init\n    driver_module.init()\n  File \"/var/azureml-app/source_directory/x/y/score_local.py\", line 55, in init\n    learner = load_learner(model_path_file_hc)\n  File \"/azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/python3.6/site-packages/fastai/learner.py\", line 539, in load_learner\n    res = torch.load(fname, map_location='cpu' if cpu else None)\n  File \"/azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/python3.6/site-packages/torch/serialization.py\", line 571, in load\n    with _open_file_like(f, 'rb') as opened_file:\n  File \"/azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/python3.6/site-packages/torch/serialization.py\", line 229, in _open_file_like\n    return _open_file(name_or_buffer, mode)\n  File \"/azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/python3.6/site-packages/torch/serialization.py\", line 210, in __init__\n    super(_open_file, self).__init__(open(name, mode))\nFileNotFoundError: [Errno 2] No such file or directory: './source_directory/azureml-models/breastcancerfastai/1/export.pkl'\n\nWorker exiting (pid: 45)\nShutting down: Master\nReason: Worker failed to boot.\n2020-09-22T18:49:09,317083600+00:00 - gunicorn/finish 3 0\n2020-09-22T18:49:09,318517500+00:00 - Exit code 3 is not normal. Killing image.\n\n"
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-51a4b194522e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlocal_service\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mservice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlocal_service\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\azureml\\core\\webservice\\local.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[0;32m     70\u001b[0m                                           logger=module_logger)\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\azureml\\core\\webservice\\local.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[1;34m(self, show_output)\u001b[0m\n\u001b[0;32m    601\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m                                    \u001b[0mhealth_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_base_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m                                    cleanup_if_failed=False)\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTATE_RUNNING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\azureml\\_model_management\\_util.py\u001b[0m in \u001b[0;36mcontainer_health_check\u001b[1;34m(docker_port, container, health_url, cleanup_if_failed)\u001b[0m\n\u001b[0;32m    745\u001b[0m             \u001b[1;31m# The container has started and crashed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m             _raise_for_container_failure(container, cleanup_if_failed,\n\u001b[1;32m--> 747\u001b[1;33m                                          'Error: Container has crashed. Did your init method fail?')\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[1;31m# The container hasn't crashed, so try to ping the health endpoint.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\azureml\\_model_management\\_util.py\u001b[0m in \u001b[0;36m_raise_for_container_failure\u001b[1;34m(container, cleanup, message)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         \u001b[0mcleanup_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1260\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}"
          ]
        }
      ],
      "source": [
        "from azureml.core.webservice import LocalWebservice\n",
        "\n",
        "# This is optional, if not provided Docker will choose a random unused port.\n",
        "deployment_config = LocalWebservice.deploy_configuration(port=6789)\n",
        "\n",
        "local_service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
        "\n",
        "local_service.wait_for_deployment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print('Local service port: {}'.format(local_service.port))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check Status and Get Container Logs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2020-09-22T19:19:14,569747500+00:00 - gunicorn/run \n2020-09-22T19:19:14,570339200+00:00 - rsyslog/run \n2020-09-22T19:19:14,570660200+00:00 - iot-server/run \n2020-09-22T19:19:14,577043300+00:00 - nginx/run \n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2020-09-22T19:19:14,685871200+00:00 - iot-server/finish 1 0\n2020-09-22T19:19:14,687683000+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 19.9.0\nListening at: http://127.0.0.1:31311 (11)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 45\nSPARK_HOME not set. Skipping PySpark Initialization.\nGenerating new fontManager, this may take some time...\nInitializing logger\n2020-09-22 19:19:17,480 | root | INFO | Starting up app insights client\nStarting up app insights client\n2020-09-22 19:19:17,480 | root | INFO | Starting up request id generator\nStarting up request id generator\n2020-09-22 19:19:17,481 | root | INFO | Starting up app insight hooks\nStarting up app insight hooks\n2020-09-22 19:19:17,481 | root | INFO | Invoking user's init function\nInvoking user's init function\nAZUREML_MODEL_DIR-Model_Path: azureml-models/breastcancerfastai_local03/1\nModel_Path_File: azureml-models/breastcancerfastai_local03/1/export.pkl\nModel_Path_File_HC: ./source_directory/azureml-models/breastcancerfastai/1/export_breast_092220.pkl\nFastAI Version: 2.0.6\nPath(): .\nazureml-models\nsource_directory\n__pycache__\nmain.py\nmodel_config_map.json\n./azureml-models\n./source_directory\n./__pycache__\n./main.py\n./model_config_map.json\n./azureml-models/breastcancerfastai_local03\n./azureml-models/breastcancerfastai_local03/1\n./azureml-models/breastcancerfastai_local03/1/export.pkl\n./source_directory/azureml-models\n./source_directory/dockerstep\n./source_directory/env\n./source_directory/x\n./source_directory/azureml-models/breastcancerfastai\n./source_directory/azureml-models/breastcancerfastai/1\n./source_directory/azureml-models/breastcancerfastai/1/export_breast_092220.pkl\n./source_directory/x/y\n./source_directory/x/y/__pycache__\n./source_directory/x/y/score_local.py\n./source_directory/x/y/__pycache__/score_local.cpython-36.pyc\n./__pycache__/main.cpython-36.pyc\n(#2) ['Negative','Positive']\n2020-09-22 19:19:19,026 | root | INFO | Users's init has completed successfully\nUsers's init has completed successfully\n2020-09-22 19:19:19,028 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\nSkipping middleware: dbg_model_info as it's not enabled.\n2020-09-22 19:19:19,029 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\nSkipping middleware: dbg_resource_usage as it's not enabled.\n2020-09-22 19:19:19,029 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\nScoring timeout setting is not found. Use default timeout: 3600000 ms\n\n"
        }
      ],
      "source": [
        "print(local_service.get_logs())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Web Service"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Call the web service with some input data to get a prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Checking container health...\nLocal webservice is running at http://localhost:6789\nTest,Positive\n"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "sample_input = 'Testing Data'\n",
        "\n",
        "print(local_service.run(sample_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reload Service\n",
        "\n",
        "You can update your score.py file and then call `reload()` to quickly restart the service. This will only reload your execution script and dependency files, it will not rebuild the underlying Docker image. As a result, `reload()` is fast, but if you do need to rebuild the image -- to add a new Conda or pip package, for instance -- you will have to call `update()`, instead (see below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%writefile source_directory/x/y/score_template.py\n",
        "import joblib\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_regression_local.pkl')\n",
        "    # Deserialize the model file back into a sklearn model.\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "    global name, from_location\n",
        "    # Note here, the entire source directory from inference config gets added into image.\n",
        "    # Below is an example of how you can use any extra files in image.\n",
        "    with open('source_directory/extradata.json') as json_file:  \n",
        "        data = json.load(json_file)\n",
        "        name = data[\"people\"][0][\"name\"]\n",
        "        from_location = data[\"people\"][0][\"from\"]\n",
        "\n",
        "input_sample = np.array([[10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0]])\n",
        "output_sample = np.array([3726.995])\n",
        "\n",
        "@input_schema('data', NumpyParameterType(input_sample))\n",
        "@output_schema(NumpyParameterType(output_sample))\n",
        "def run(data):\n",
        "    try:\n",
        "        result = model.predict(data)\n",
        "        # You can return any JSON-serializable object.\n",
        "        return \"Hello \" + name + \" from \" + from_location + \" here is your result = \" + str(result)\n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Container has been successfully cleaned up.\n"
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "(232, 'WriteFile', 'The pipe is being closed.')",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-31-ad4d56fd04ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlocal_service\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--------------------------------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\azureml\\core\\webservice\\local.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[0;32m     70\u001b[0m                                           logger=module_logger)\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\azureml\\core\\webservice\\local.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self, wait)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mraises\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWebserviceException\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \"\"\"\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_in_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSTATE_DEPLOYING\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTATE_RUNNING\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\azureml\\core\\webservice\\local.py\u001b[0m in \u001b[0;36m_run_container\u001b[1;34m(self, wait)\u001b[0m\n\u001b[0;32m    955\u001b[0m                                             \u001b[0menvironment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menvironment\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m                                             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                                             ports=ports)\n\u001b[0m\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m         \u001b[1;31m# Copy local assets into the AML working directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\azureml\\_model_management\\_util.py\u001b[0m in \u001b[0;36mcreate_docker_container\u001b[1;34m(docker_client, image_location, container_name, auto_remove, environment, labels, ports, volumes)\u001b[0m\n\u001b[0;32m    469\u001b[0m                                                \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m                                                \u001b[0mports\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mports\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m                                                volumes=volumes)\n\u001b[0m\u001b[0;32m    472\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mdocker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAPIError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Docker container create has failed:\\n{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\models\\containers.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, image, command, **kwargs)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'version'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[0mcreate_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_create_container_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcreate_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\api\\container.py\u001b[0m in \u001b[0;36mcreate_container\u001b[1;34m(self, image, command, hostname, user, detach, stdin_open, tty, ports, environment, volumes, network_disabled, name, entrypoint, working_dir, domainname, host_config, mac_address, labels, stop_signal, networking_config, healthcheck, stop_timeout, runtime, use_config_proxy)\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[0mstop_timeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         )\n\u001b[1;32m--> 430\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_container_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_container_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\api\\container.py\u001b[0m in \u001b[0;36mcreate_container_from_config\u001b[1;34m(self, config, name)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         }\n\u001b[1;32m--> 440\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\api\\client.py\u001b[0m in \u001b[0;36m_post_json\u001b[1;34m(self, url, data, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'headers'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'headers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Content-Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'application/json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_attach_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\utils\\decorators.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'headers'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_general_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'HttpHeaders'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\api\\client.py\u001b[0m in \u001b[0;36m_post\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mupdate_headers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_request_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mupdate_headers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \"\"\"\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'POST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m         }\n\u001b[0;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    675\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m             )\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;31m# Reset the timeout for the recv() on the socket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 encode_chunked=False):\n\u001b[0;32m   1251\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[1;31m# default charset of iso-8859-1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb\"\\r\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 987\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    988\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\transport\\npipesocket.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;34m'Can not reuse socket after connection was closed.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             )\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\transport\\npipesocket.py\u001b[0m in \u001b[0;36msendall\u001b[1;34m(self, string, flags)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcheck_closed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msendall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcheck_closed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\transport\\npipesocket.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;34m'Can not reuse socket after connection was closed.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             )\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\machinelearningnotebooks\\lib\\site-packages\\docker\\transport\\npipesocket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, string, flags)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcheck_closed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwin32file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWriteFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31merror\u001b[0m: (232, 'WriteFile', 'The pipe is being closed.')"
          ]
        }
      ],
      "source": [
        "local_service.reload()\n",
        "print(\"--------------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2020-09-22T19:19:14,569747500+00:00 - gunicorn/run \n2020-09-22T19:19:14,570339200+00:00 - rsyslog/run \n2020-09-22T19:19:14,570660200+00:00 - iot-server/run \n2020-09-22T19:19:14,577043300+00:00 - nginx/run \n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n/usr/sbin/nginx: /azureml-envs/azureml_68b223042de9a84a2da2ad7149ac35f9/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n2020-09-22T19:19:14,685871200+00:00 - iot-server/finish 1 0\n2020-09-22T19:19:14,687683000+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 19.9.0\nListening at: http://127.0.0.1:31311 (11)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 45\nSPARK_HOME not set. Skipping PySpark Initialization.\nGenerating new fontManager, this may take some time...\nInitializing logger\n2020-09-22 19:19:17,480 | root | INFO | Starting up app insights client\nStarting up app insights client\n2020-09-22 19:19:17,480 | root | INFO | Starting up request id generator\nStarting up request id generator\n2020-09-22 19:19:17,481 | root | INFO | Starting up app insight hooks\nStarting up app insight hooks\n2020-09-22 19:19:17,481 | root | INFO | Invoking user's init function\nInvoking user's init function\nAZUREML_MODEL_DIR-Model_Path: azureml-models/breastcancerfastai_local03/1\nModel_Path_File: azureml-models/breastcancerfastai_local03/1/export.pkl\nModel_Path_File_HC: ./source_directory/azureml-models/breastcancerfastai/1/export_breast_092220.pkl\nFastAI Version: 2.0.6\nPath(): .\nazureml-models\nsource_directory\n__pycache__\nmain.py\nmodel_config_map.json\n./azureml-models\n./source_directory\n./__pycache__\n./main.py\n./model_config_map.json\n./azureml-models/breastcancerfastai_local03\n./azureml-models/breastcancerfastai_local03/1\n./azureml-models/breastcancerfastai_local03/1/export.pkl\n./source_directory/azureml-models\n./source_directory/dockerstep\n./source_directory/env\n./source_directory/x\n./source_directory/azureml-models/breastcancerfastai\n./source_directory/azureml-models/breastcancerfastai/1\n./source_directory/azureml-models/breastcancerfastai/1/export_breast_092220.pkl\n./source_directory/x/y\n./source_directory/x/y/__pycache__\n./source_directory/x/y/score_local.py\n./source_directory/x/y/__pycache__/score_local.cpython-36.pyc\n./__pycache__/main.cpython-36.pyc\n(#2) ['Negative','Positive']\n2020-09-22 19:19:19,026 | root | INFO | Users's init has completed successfully\nUsers's init has completed successfully\n2020-09-22 19:19:19,028 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\nSkipping middleware: dbg_model_info as it's not enabled.\n2020-09-22 19:19:19,029 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\nSkipping middleware: dbg_resource_usage as it's not enabled.\n2020-09-22 19:19:19,029 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\nScoring timeout setting is not found. Use default timeout: 3600000 ms\n\n"
        }
      ],
      "source": [
        "print(local_service.get_logs())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# After calling reload(), run() will return the updated message.\n",
        "local_service.run('Testing')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Update Service\n",
        "\n",
        "If you want to change your model(s), Conda dependencies, or deployment configuration, call `update()` to rebuild the Docker image.\n",
        "\n",
        "```python\n",
        "\n",
        "local_service.update(models=[SomeOtherModelObject],\n",
        "                     deployment_config=local_config,\n",
        "                     inference_config=inference_config)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "local_service.update(inference_config=inference_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete Service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "local_service.delete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "keriehm"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3.7.7 64-bit ('machinelearningnotebooks': conda)",
      "language": "python",
      "name": "python_defaultSpec_1600745472250"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7-final"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}